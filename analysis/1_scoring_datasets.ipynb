{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1de18d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc='Cleaning')\n",
    "\n",
    "from scorers.cleaning import *\n",
    "from scorers.specificity_vs_vagueness import *\n",
    "from scorers.objectivity_vs_subjectivity import *\n",
    "from scorers.rationality_vs_emotionality import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62e6529e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading and cleaning datasets\n",
    "\n",
    "# Manifestos\n",
    "manifestos = pd.read_csv('../manifesto-forewords/manifestos.csv')\n",
    "manifestos.year = pd.to_datetime(manifestos.year)\n",
    "manifestos = manifestos[manifestos.year>='1945-01-01']\n",
    "# PMQs answers\n",
    "pmqs = pd.read_csv('../hansard-pmqs/hansard_pmqs.csv')\n",
    "pmqs.date = pd.to_datetime(pmqs.date)\n",
    "pmqs = pmqs[pmqs.date>='1945-01-01']\n",
    "pmqs = pd.DataFrame({'date':pmqs.groupby(by='date').answer_text.aggregate(lambda x: ''.join(x)).index,\n",
    "                     'answer_text':pmqs.groupby(by='date').answer_text.aggregate(lambda x: ''.join(x)),\n",
    "                     'answerer_party':pmqs.groupby(by='date').answerer_party.aggregate(lambda x: x.mode()),\n",
    "                     'answerer_name':pmqs.groupby(by='date').answerer_name.aggregate(lambda x: x.mode())})\n",
    "# Conference speeches\n",
    "conferences = pd.read_csv('../conference-speeches/conference.csv')\n",
    "conferences = conferences.drop('Unnamed: 0', axis=1)\n",
    "conferences.year = conferences.year.apply(lambda year: pd.to_datetime(str(year)+'-01-01'))\n",
    "conferences = conferences[conferences.year>='1945-01-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffbf3776",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning: 100%|██████████████████████████████████████████████████████████████████████| 76/76 [00:00<00:00, 6870.87it/s]\n",
      "Scoring manifestos: 100%|██████████████████████████████████████████████████████████████| 76/76 [00:01<00:00, 43.94it/s]\n",
      "Saving manifesto scores: 100%|█████████████████████████████████████████████████████████████████| 76/76 [00:00<?, ?it/s]\n",
      "Cleaning: 100%|██████████████████████████████████████████████████████████████████| 1806/1806 [00:00<00:00, 2344.29it/s]\n",
      "Scoring PMQs answers: 100%|████████████████████████████████████████████████████████| 1806/1806 [00:18<00:00, 97.33it/s]\n",
      "Saving PMQs answer scores: 100%|████████████████████████████████████████████████| 1806/1806 [00:00<00:00, 51395.06it/s]\n",
      "Cleaning: 100%|█████████████████████████████████████████████████████████████████████| 183/183 [00:00<00:00, 809.74it/s]\n",
      "Scoring conference speeches: 100%|███████████████████████████████████████████████████| 183/183 [00:05<00:00, 31.85it/s]\n",
      "Saving conference speech scores: 100%|████████████████████████████████████████████| 183/183 [00:00<00:00, 14049.86it/s]\n"
     ]
    }
   ],
   "source": [
    "## Scoring for specificity vs. vagueness\n",
    "\n",
    "# Manifestos\n",
    "manifestos_clean = manifestos.foreword.progress_apply(lambda x: clean(x)) # ...clean them\n",
    "manifestos_nans = [idx for idx,foreword in enumerate(manifestos_clean) if len(foreword)==0] # ...save NAN indexes to a list\n",
    "manifestos_scores = [measure_vagueness(foreword) for foreword in tqdm(manifestos_clean,desc='Scoring manifestos') if len(foreword)>0] # ...score them\n",
    "manifestos_vecs = [list(score_dict.values()) for score_dict in tqdm(manifestos_scores,desc='Saving manifesto scores')] # ...save scores as a list\n",
    "# PMQs answers\n",
    "pmqs_clean = pmqs.answer_text.progress_apply(lambda x: clean(x))\n",
    "pmqs_nans = [idx for idx,answer in enumerate(pmqs_clean) if len(answer)==0]\n",
    "pmqs_scores = [measure_vagueness(answer) for answer in tqdm(pmqs_clean,desc='Scoring PMQs answers') if len(answer)>0]\n",
    "pmqs_vecs = [list(score_dict.values()) for score_dict in tqdm(pmqs_scores,desc='Saving PMQs answer scores')]\n",
    "# Conference speeches\n",
    "conferences_clean = conferences.content.progress_apply(lambda x: clean(x))\n",
    "conferences_nans = [idx for idx,speech in enumerate(conferences_clean) if len(speech)==0]\n",
    "conferences_scores = [measure_vagueness(speech) for speech in tqdm(conferences_clean,desc='Scoring conference speeches') if len(speech)>0]\n",
    "conferences_vecs = [list(score_dict.values()) for score_dict in tqdm(conferences_scores,desc='Saving conference speech scores')]\n",
    "\n",
    "for key,value in {key:[score_dict[key] for score_dict in manifestos_scores] for key in manifestos_scores[0].keys()}.items():\n",
    "    manifestos[\"vague_\"+key] = value\n",
    "for key,value in {key:[score_dict[key] for score_dict in pmqs_scores] for key in pmqs_scores[0].keys()}.items():\n",
    "    pmqs[\"vague_\"+key] = value\n",
    "for key,value in {key:[score_dict[key] for score_dict in conferences_scores] for key in conferences_scores[0].keys()}.items():\n",
    "    conferences[\"vague_\"+key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b8692e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning: 100%|██████████████████████████████████████████████████████████████████████| 76/76 [00:00<00:00, 4450.00it/s]\n",
      "Scoring manifesto forewords: 76it [00:04, 16.68it/s]\n",
      "Saving manifesto scores: 100%|██████████████████████████████████████████████████████| 76/76 [00:00<00:00, 75662.74it/s]\n",
      "Cleaning: 100%|██████████████████████████████████████████████████████████████████| 1806/1806 [00:00<00:00, 2415.66it/s]\n",
      "Scoring PMQs answers: 1806it [05:30,  5.47it/s]\n",
      "Saving PMQs answer scores: 100%|███████████████████████████████████████████████| 1806/1806 [00:00<00:00, 600325.96it/s]\n",
      "Cleaning: 100%|█████████████████████████████████████████████████████████████████████| 183/183 [00:00<00:00, 809.05it/s]\n",
      "Scoring conference speeches: 183it [01:34,  1.93it/s]\n",
      "Saving conference speech scores: 100%|███████████████████████████████████████████████████████| 183/183 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "## Scoring for objectivity vs. subjectivity\n",
    "\n",
    "# Manifestos\n",
    "manifestos['clean'] = manifestos.foreword.progress_apply(lambda x: clean(x)) # ...clean them\n",
    "manifestos_nans = [idx for idx,foreword in enumerate(manifestos['clean']) if len(foreword)==0] # ...save NAN indexes to a list\n",
    "manifestos_scores = [measure_subjectivity(text_list=row.clean, raw_text=row.foreword) for idx,row in tqdm(manifestos.iterrows(),desc='Scoring manifesto forewords') if len(row.clean)>0] # ...score them\n",
    "manifestos_vecs = [list(score_dict.values()) for score_dict in tqdm(manifestos_scores,desc='Saving manifesto scores')] # ...save scores as a list\n",
    "# # PMQs answers\n",
    "pmqs['clean'] = pmqs.answer_text.progress_apply(lambda x: clean(x))\n",
    "pmqs_nans = [idx for idx,answer in enumerate(pmqs['clean']) if len(answer)==0]\n",
    "pmqs_scores = [measure_subjectivity(text_list=row.clean, raw_text=row.answer_text) for idx,row in tqdm(pmqs.iterrows(),desc='Scoring PMQs answers') if len(row.clean)>0]\n",
    "pmqs_vecs = [list(score_dict.values()) for score_dict in tqdm(pmqs_scores,desc='Saving PMQs answer scores')]\n",
    "# # Conference speeches\n",
    "conferences['clean'] = conferences.content.progress_apply(lambda x: clean(x))\n",
    "conferences_nans = [idx for idx,speech in enumerate(conferences['clean']) if len(speech)==0]\n",
    "conferences_scores = [measure_subjectivity(text_list=row.clean, raw_text=row.content) for idx,row in tqdm(conferences.iterrows(),desc='Scoring conference speeches') if len(row.clean)>0]\n",
    "conferences_vecs = [list(score_dict.values()) for score_dict in tqdm(conferences_scores,desc='Saving conference speech scores')]\n",
    "\n",
    "for key,value in {key:[score_dict[key] for score_dict in manifestos_scores] for key in manifestos_scores[0].keys()}.items():\n",
    "    manifestos[\"subj_\"+key] = value\n",
    "for key,value in {key:[score_dict[key] for score_dict in pmqs_scores] for key in pmqs_scores[0].keys()}.items():\n",
    "    pmqs[\"subj_\"+key] = value\n",
    "for key,value in {key:[score_dict[key] for score_dict in conferences_scores] for key in conferences_scores[0].keys()}.items():\n",
    "    conferences[\"subj_\"+key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bccc3866",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning: 100%|██████████████████████████████████████████████████████████████████████| 76/76 [00:00<00:00, 4470.85it/s]\n",
      "Scoring manifesto forewords: 76it [00:07, 10.73it/s]\n",
      "Saving manifesto scores: 100%|██████████████████████████████████████████████████████| 76/76 [00:00<00:00, 76296.58it/s]\n",
      "Cleaning: 100%|██████████████████████████████████████████████████████████████████| 1806/1806 [00:00<00:00, 2297.89it/s]\n",
      "Scoring PMQs answers: 1806it [08:33,  3.51it/s]\n",
      "Saving PMQs answer scores: 100%|███████████████████████████████████████████████| 1806/1806 [00:00<00:00, 602282.98it/s]\n",
      "Cleaning: 100%|█████████████████████████████████████████████████████████████████████| 183/183 [00:00<00:00, 793.26it/s]\n",
      "Scoring conference speeches: 183it [02:32,  1.20it/s]\n",
      "Saving conference speech scores: 100%|███████████████████████████████████████████████████████| 183/183 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "## Scoring for rationality vs. emotionality\n",
    "\n",
    "# Manifestos\n",
    "manifestos['clean'] = manifestos.foreword.progress_apply(lambda x: clean(x)) # ...clean them\n",
    "manifestos_nans = [idx for idx,foreword in enumerate(manifestos['clean']) if len(foreword)==0] # ...save NAN indexes to a list\n",
    "manifestos_scores = [measure_emotionality(text_list=row.clean, raw_text=row.foreword) for idx,row in tqdm(manifestos.iterrows(),desc='Scoring manifesto forewords') if len(row.clean)>0] # ...score them\n",
    "manifestos_vecs = [list(score_dict.values()) for score_dict in tqdm(manifestos_scores,desc='Saving manifesto scores')] # ...save scores as a list\n",
    "# # PMQs answers\n",
    "pmqs['clean'] = pmqs.answer_text.progress_apply(lambda x: clean(x))\n",
    "pmqs_nans = [idx for idx,answer in enumerate(pmqs['clean']) if len(answer)==0]\n",
    "pmqs_scores = [measure_emotionality(text_list=row.clean, raw_text=row.answer_text) for idx,row in tqdm(pmqs.iterrows(),desc='Scoring PMQs answers') if len(row.clean)>0]\n",
    "pmqs_vecs = [list(score_dict.values()) for score_dict in tqdm(pmqs_scores,desc='Saving PMQs answer scores')]\n",
    "# # Conference speeches\n",
    "conferences['clean'] = conferences.content.progress_apply(lambda x: clean(x))\n",
    "conferences_nans = [idx for idx,speech in enumerate(conferences['clean']) if len(speech)==0]\n",
    "conferences_scores = [measure_emotionality(text_list=row.clean, raw_text=row.content) for idx,row in tqdm(conferences.iterrows(),desc='Scoring conference speeches') if len(row.clean)>0]\n",
    "conferences_vecs = [list(score_dict.values()) for score_dict in tqdm(conferences_scores,desc='Saving conference speech scores')]\n",
    "\n",
    "for key,value in {key:[score_dict[key] for score_dict in manifestos_scores] for key in manifestos_scores[0].keys()}.items():\n",
    "    manifestos[\"emot_\"+key] = value\n",
    "for key,value in {key:[score_dict[key] for score_dict in pmqs_scores] for key in pmqs_scores[0].keys()}.items():\n",
    "    pmqs[\"emot_\"+key] = value\n",
    "for key,value in {key:[score_dict[key] for score_dict in conferences_scores] for key in conferences_scores[0].keys()}.items():\n",
    "    conferences[\"emot_\"+key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5512d97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save datasets\n",
    "\n",
    "# Individually...\n",
    "manifestos.to_csv('scored_datasets/manifestos.csv', index=False)\n",
    "pmqs.to_csv('scored_datasets/pmqs.csv', index=False)\n",
    "conferences.to_csv('scored_datasets/conferences.csv', index=False)\n",
    "\n",
    "# And merged...\n",
    "party_dict = {'Labour':'LAB',\n",
    "              'Conservative':'CON',\n",
    "              'Liberal':'LIB',\n",
    "              'SDP-Liberal Alliance':'LIB',\n",
    "              'Liberal Democrat':'LIB',\n",
    "              np.nan:'NAN'}\n",
    "\n",
    "score_vars = [colname for colname in manifestos.columns if any([prefix in colname for prefix in ['vague','subj','emot']])]\n",
    "score_dict = {'type':[],'year':[],'party':[]}\n",
    "score_dict.update({score_var:[] for score_var in score_vars})\n",
    "score_df = pd.DataFrame(score_dict)\n",
    "\n",
    "manifesto_dict = {'type':['manifesto']*len(manifestos_vecs),\n",
    "                  'year':manifestos.drop(manifestos_nans, axis=0).year,\n",
    "                  'party':manifestos.drop(manifestos_nans, axis=0).party}\n",
    "manifesto_dict.update({score_var:manifestos[score_var] for score_var in score_vars})\n",
    "manifesto_df = pd.DataFrame(manifesto_dict)\n",
    "\n",
    "pmqs_dict = {'type':['PMQs']*len(pmqs_vecs),\n",
    "             'year':pmqs.drop(pmqs_nans, axis=0).date,\n",
    "             'party':pmqs.drop(pmqs_nans, axis=0).answerer_party.apply(lambda party: party_dict[str(party)] if str(party) in party_dict.keys() else 'NAN')}\n",
    "pmqs_dict.update({score_var:pmqs[score_var] for score_var in score_vars})\n",
    "pmqs_df = pd.DataFrame(pmqs_dict)\n",
    "\n",
    "conferences_dict = {'type':['conference']*len(conferences_vecs),\n",
    "                    'year':conferences.drop(conferences_nans, axis=0).year,\n",
    "                    'party':conferences.drop(conferences_nans, axis=0).party.apply(lambda party: party_dict[party])}\n",
    "conferences_dict.update({score_var:conferences[score_var] for score_var in score_vars})\n",
    "conferences_df = pd.DataFrame(conferences_dict)\n",
    "\n",
    "for df in [manifesto_df,pmqs_df,conferences_df]:\n",
    "    score_df = score_df.append(df)\n",
    "    \n",
    "score_df.to_csv('scored_datasets/combined.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
