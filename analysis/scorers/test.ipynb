{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d73651ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Load pre-trained TensorFlow model\n",
    "saved_model_path = '/objectivity_vs_subjectivity/subjectivity_classifier/'\n",
    "subjectivity_estimator = tf.saved_model.load(saved_model_path)\n",
    "\n",
    "# Speculative cues taken from \n",
    "speculative_cues = ['may','might','can','would','should','could',\n",
    "                    'think','suggest','question','presume',\n",
    "                    'suspect','indicate','suppose','seem','appear','expect',\n",
    "                    'probable','likely','possible','apparently','unsure',\n",
    "                    'if','or','and/or','either','versus','vs']\n",
    "\n",
    "# Modal verbs taken from Cambridge Dictionary (2022) 'Modal verbs and modality'\n",
    "modal_verb_list = ['can','could','may','might','will','shall','would','should','must',\n",
    "                   'dare','need','ought','used','going','able']\n",
    "\n",
    "# Subjective adjectives taken from Wiebe (2000) 'Learning subjective adjectives from corpora'\n",
    "subjective_adjective_list = pd.read_csv('https://people.cs.pitt.edu/~wiebe/pubs/aaai00/adjsMPQA', header=None)[0].to_list()\n",
    "subjective_adjective_list = [word.strip() for word in subjective_adjective_list]\n",
    "\n",
    "def measure_subjective_sentence_freq(sent_list):\n",
    "    subjective_sent_count = None\n",
    "    return subjective_sent_count/len(sent_list)\n",
    "\n",
    "def measure_speculative_sentence_freq(sent_list, speculative_cues=speculative_cues):\n",
    "    wnl = WordNetLemmatizer()\n",
    "    lemmatised_sent_list = [[wnl.lemmatize(word) for word in sent] for sent in sent_list]\n",
    "    speculative_sent_count = sum([1 for lemma_sent in lemmatised_sent_list if any([lemma in speculative_cues for lemma in lemma_sent])])\n",
    "    return speculative_sent_count/len(sent_list)\n",
    "\n",
    "def measure_modal_verb_freq(text_list, modal_verb_list=modal_verb_list):\n",
    "    modal_verb_count = sum([word in modal_verb_list for word in text_list])\n",
    "    return modal_verb_count/len(text_list)\n",
    "\n",
    "def measure_subjective_adjective_freq(text_list, subjective_adjective_list=subjective_adjective_list):\n",
    "    subjective_adjective_count = sum([word in subjective_adjective_list for word in text_list])\n",
    "    return subjective_adjective_count/len(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "124e00fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High speculation frequency: 100.0%\n",
      "Low speculation frequency: 0.0%\n"
     ]
    }
   ],
   "source": [
    "high_freq = measure_speculative_sentence_freq([['this','sentence','can','have','more','speculative','cues'],\n",
    "                                               ['however','i','think','that','this','sentence','has','enough']])\n",
    "low_freq = measure_speculative_sentence_freq([['this','sentence','has','no','speculative','cues'],\n",
    "                                              ['this','sentence','has','none','also']])\n",
    "print(\"High speculation frequency: {:.1%}\".format(high_freq))\n",
    "print(\"Low speculation frequency: {:.1%}\".format(low_freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2051ece6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High modal frequency: 30.0%\n",
      "Low modal frequency: 0.0%\n"
     ]
    }
   ],
   "source": [
    "high_freq = measure_modal_verb_freq(['this','sentence','would','have','ought','to','need','more','modal','verbs'])\n",
    "low_freq = measure_modal_verb_freq(['this','sentence','has','not','got','any','modal','verbs'])\n",
    "print(\"High modal frequency: {:.1%}\".format(high_freq))\n",
    "print(\"Low modal frequency: {:.1%}\".format(low_freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46518808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High subj. adj. frequency: 11.1%\n",
      "Low subj. adj. frequency: 0.0%\n"
     ]
    }
   ],
   "source": [
    "high_freq = measure_subjective_adjective_freq(['this','sentence','has','an','extraordinary','number','of','subjective','adjectives'])\n",
    "low_freq = measure_subjective_adjective_freq(['this','sentence','has','not','got','any','subjective','adjectives'])\n",
    "print(\"High subj. adj. frequency: {:.1%}\".format(high_freq))\n",
    "print(\"Low subj. adj. frequency: {:.1%}\".format(low_freq))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
