{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fc76d1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import regex as re\n",
    "import os\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from cleaning import *\n",
    "\n",
    "# Load pre-trained TensorFlow model\n",
    "saved_model_path = os.path.join(os.getcwd(),'objectivity_vs_subjectivity\\subjectivity_classifier')\n",
    "subjectivity_estimator = tf.saved_model.load(saved_model_path)\n",
    "\n",
    "# Speculative cues taken from \n",
    "speculative_cues = ['may','might','can','would','should','could',\n",
    "                    'think','suggest','question','presume',\n",
    "                    'suspect','indicate','suppose','seem','appear','expect',\n",
    "                    'probable','likely','possible','apparently','unsure',\n",
    "                    'if','or','and/or','either','versus','vs']\n",
    "\n",
    "# Modal verbs taken from Cambridge Dictionary (2022) 'Modal verbs and modality'\n",
    "modal_verb_list = ['can','could','may','might','will','shall','would','should','must',\n",
    "                   'dare','need','ought','used','going','able']\n",
    "\n",
    "# Subjective adjectives taken from Wiebe (2000) 'Learning subjective adjectives from corpora'\n",
    "subjective_adjective_list = pd.read_csv('https://people.cs.pitt.edu/~wiebe/pubs/aaai00/adjsMPQA', header=None)[0].to_list()\n",
    "subjective_adjective_list = [word.strip() for word in subjective_adjective_list]\n",
    "\n",
    "def measure_subjective_sentence_freq(sent_list, subjectivity_estimator=subjectivity_estimator):\n",
    "    subjectivity_predictions = []\n",
    "    # For each sentence:\n",
    "    for sent in sent_list:\n",
    "        example = tf.train.Example() # ...prepare an example for the sentence to be wrapped in\n",
    "        example.features.feature['sentence'].bytes_list.value.extend([bytes(sent, \"utf-16\")]) # ...encode the sentence as UTF-18\n",
    "        subjectivity_predictions.append(subjectivity_estimator.signatures['predict'](examples=tf.constant([example.SerializeToString()]))['class_ids'][0][0].numpy()) # ...append subjectivity prediction to list\n",
    "    return sum(subjectivity_predictions)/len(subjectivity_predictions)\n",
    "\n",
    "def measure_avg_subjective_sentence_score(sent_list, subjectivity_estimator=subjectivity_estimator):\n",
    "    subjectivity_predictions = []\n",
    "    # For each sentence:\n",
    "    for sent in sent_list:\n",
    "        example = tf.train.Example() # ...prepare an example for the sentence to be wrapped in\n",
    "        example.features.feature['sentence'].bytes_list.value.extend([bytes(sent, \"utf-16\")]) # ...encode the sentence as UTF-18\n",
    "        subjectivity_predictions.append(subjectivity_estimator.signatures['predict'](examples=tf.constant([example.SerializeToString()]))['probabilities'][0][1].numpy()) # ...append subjectivity score to list\n",
    "    return mean(subjectivity_predictions)\n",
    "\n",
    "def measure_speculative_sentence_freq(sent_list, speculative_cues=speculative_cues):\n",
    "    wnl = WordNetLemmatizer()\n",
    "    cleaned_sent_list = [clean(sent) for sent in sent_list]\n",
    "    lemmatised_sent_list = [[wnl.lemmatize(word) for word in sent] for sent in cleaned_sent_list]\n",
    "    speculative_sent_count = sum([1 for lemma_sent in lemmatised_sent_list if any([lemma in speculative_cues for lemma in lemma_sent])])\n",
    "    return speculative_sent_count/len(sent_list)\n",
    "\n",
    "def measure_modal_verb_freq(text_list, modal_verb_list=modal_verb_list):\n",
    "    modal_verb_count = sum([word in modal_verb_list for word in text_list])\n",
    "    return modal_verb_count/len(text_list)\n",
    "\n",
    "def measure_subjective_adjective_freq(text_list, subjective_adjective_list=subjective_adjective_list):\n",
    "    subjective_adjective_count = sum([word in subjective_adjective_list for word in text_list])\n",
    "    return subjective_adjective_count/len(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f0dee3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High speculation frequency: 100.0%\n",
      "Low speculation frequency: 0.0%\n"
     ]
    }
   ],
   "source": [
    "high_freq = measure_speculative_sentence_freq(['This sentence could have more speculative clues',\n",
    "                                               'However, I think this sentence probably has enough'])\n",
    "low_freq = measure_speculative_sentence_freq(['This sentence has no speculative clues',\n",
    "                                              'This sentence has none also'])\n",
    "print(\"High speculation frequency: {:.1%}\".format(high_freq))\n",
    "print(\"Low speculation frequency: {:.1%}\".format(low_freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "36c805c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High modal frequency: 30.0%\n",
      "Low modal frequency: 0.0%\n"
     ]
    }
   ],
   "source": [
    "high_freq = measure_modal_verb_freq(['this','sentence','would','have','ought','to','need','more','modal','verbs'])\n",
    "low_freq = measure_modal_verb_freq(['this','sentence','has','not','got','any','modal','verbs'])\n",
    "print(\"High modal frequency: {:.1%}\".format(high_freq))\n",
    "print(\"Low modal frequency: {:.1%}\".format(low_freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f6b72a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High subj. adj. frequency: 11.1%\n",
      "Low subj. adj. frequency: 0.0%\n"
     ]
    }
   ],
   "source": [
    "high_freq = measure_subjective_adjective_freq(['this','sentence','has','an','extraordinary','number','of','subjective','adjectives'])\n",
    "low_freq = measure_subjective_adjective_freq(['this','sentence','has','not','got','any','subjective','adjectives'])\n",
    "print(\"High subj. adj. frequency: {:.1%}\".format(high_freq))\n",
    "print(\"Low subj. adj. frequency: {:.1%}\".format(low_freq))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
