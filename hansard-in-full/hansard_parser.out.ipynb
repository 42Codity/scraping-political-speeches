{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02cbefc6",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [4]</a>'.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30be5a47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T04:35:56.047468Z",
     "iopub.status.busy": "2025-10-04T04:35:56.047180Z",
     "iopub.status.idle": "2025-10-04T04:35:57.971101Z",
     "shell.execute_reply": "2025-10-04T04:35:57.970659Z"
    },
    "papermill": {
     "duration": 1.92986,
     "end_time": "2025-10-04T04:35:57.972303",
     "exception": false,
     "start_time": "2025-10-04T04:35:56.042443",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e662405",
   "metadata": {
    "papermill": {
     "duration": 0.00092,
     "end_time": "2025-10-04T04:35:57.975754",
     "exception": false,
     "start_time": "2025-10-04T04:35:57.974834",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Hansard parser from XML files saved to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dd8b897",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T04:35:57.978285Z",
     "iopub.status.busy": "2025-10-04T04:35:57.978083Z",
     "iopub.status.idle": "2025-10-04T04:35:57.980378Z",
     "shell.execute_reply": "2025-10-04T04:35:57.980077Z"
    },
    "papermill": {
     "duration": 0.004711,
     "end_time": "2025-10-04T04:35:57.981332",
     "exception": false,
     "start_time": "2025-10-04T04:35:57.976621",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_xml_from_path(path):\n",
    "    # Read from path - decode bytes to strings\n",
    "    with open(path, 'rb') as file:\n",
    "        xml = file.read().decode(errors='replace') # Replace unrecognised utf-8 tokens with '?'\n",
    "        \n",
    "    return xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0861cf7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T04:35:57.984152Z",
     "iopub.status.busy": "2025-10-04T04:35:57.983978Z",
     "iopub.status.idle": "2025-10-04T04:35:57.989313Z",
     "shell.execute_reply": "2025-10-04T04:35:57.988845Z"
    },
    "papermill": {
     "duration": 0.007733,
     "end_time": "2025-10-04T04:35:57.990270",
     "exception": false,
     "start_time": "2025-10-04T04:35:57.982537",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_hansard_xml(xml, memberid2personid_lookup, filter_no_speaker=True):\n",
    "    # Use BeautifulSoup to tidy the XML\n",
    "    import pandas as pd\n",
    "    from bs4 import BeautifulSoup\n",
    "    bs = BeautifulSoup(xml)\n",
    "    \n",
    "    # Define a function to parse a chunk of XML for an individual speech\n",
    "    def parse_speech_xml(speech_xml):\n",
    "        name = speech_xml.get('speakername')\n",
    "        speech_id = speech_xml.get('id')\n",
    "        person_id = speech_xml.get('person_id')\n",
    "        if pd.isna(person_id):\n",
    "            member_id = speech_xml.get('speakerid')\n",
    "            if member_id in memberid2personid_lookup.keys():\n",
    "                person_id = memberid2personid_lookup[member_id]\n",
    "        text = speech_xml.find('p')\n",
    "        if text is not None:\n",
    "            text = text.get_text()\n",
    "        return name,speech_id,person_id,text\n",
    "    \n",
    "    # Get an XML object for each speech in the debate\n",
    "    speeches = bs.find_all('speech') \n",
    "    \n",
    "    # Create dictionary to store debate features\n",
    "    debate_dict = {'name':[],\n",
    "                   'speech_id':[],\n",
    "                   'person_id':[],\n",
    "                   'text':[]}\n",
    "    \n",
    "    for speech_xml in speeches:\n",
    "        name,speech_id,person_id,text = parse_speech_xml(speech_xml)\n",
    "        if filter_no_speaker: # If we're filtering 'no speaker' lines, then drop speeches with no name\n",
    "            if name is not None:\n",
    "                for variable in debate_dict.keys():\n",
    "                    debate_dict[variable].append(eval(variable))\n",
    "        else:\n",
    "            for variable in debate_dict.keys():\n",
    "                debate_dict[variable].append(eval(variable))\n",
    "    \n",
    "    return pd.DataFrame(debate_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98c27c6",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6115f736",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-04T04:35:57.993472Z",
     "iopub.status.busy": "2025-10-04T04:35:57.993313Z",
     "iopub.status.idle": "2025-10-04T04:35:58.823448Z",
     "shell.execute_reply": "2025-10-04T04:35:58.822857Z"
    },
    "papermill": {
     "duration": 0.832585,
     "end_time": "2025-10-04T04:35:58.824231",
     "exception": true,
     "start_time": "2025-10-04T04:35:57.991646",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                        | 0/13976 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|██████████████████████▏                                                   | 4184/13976 [00:00<00:00, 41830.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|████████████████████████████████████████████▎                             | 8368/13976 [00:00<00:00, 39700.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████████████████████████████████████████████████████████████▍        | 12346/13976 [00:00<00:00, 39302.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|█████████████████████████████████████████████████████████████████████████| 13976/13976 [00:00<00:00, 39748.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                        | 0/19646 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                        | 0/19646 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[32m/var/folders/nl/ddy2lswn35n0lgm806bb2tz80000gn/T/ipykernel_92988/690475114.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     14\u001b[39m \n\u001b[32m     15\u001b[39m     speech_xml = read_xml_from_path(filename)\n\u001b[32m     16\u001b[39m     debate_df = parse_hansard_xml(speech_xml, memberid2personid_lookup)\n\u001b[32m     17\u001b[39m \n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m     df = df.append(debate_df)\n\u001b[32m     19\u001b[39m \n\u001b[32m     20\u001b[39m display(df.head())\n",
      "\u001b[32m~/Documents/GitHub/scraping-political-speeches/.venv/lib/python3.13/site-packages/pandas/core/generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   6317\u001b[39m             \u001b[38;5;28;01mand\u001b[39;00m name \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01min\u001b[39;00m self._accessors\n\u001b[32m   6318\u001b[39m             \u001b[38;5;28;01mand\u001b[39;00m self._info_axis._can_hold_identifiers_and_holds_name(name)\n\u001b[32m   6319\u001b[39m         ):\n\u001b[32m   6320\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self[name]\n\u001b[32m-> \u001b[39m\u001b[32m6321\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m object.__getattribute__(self, name)\n",
      "\u001b[31mAttributeError\u001b[39m: 'DataFrame' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "people_df = pd.read_csv('people.csv').drop('Unnamed: 0',axis=1)\n",
    "\n",
    "lookup = lambda row: {member_id:row.person_id for member_id in eval(row.memberships)}\n",
    "lookup_list = people_df.progress_apply(lookup, axis=1).to_list()\n",
    "\n",
    "memberid2personid_lookup = {member_id:person_id for lookup_dict in lookup_list for member_id,person_id in lookup_dict.items()}\n",
    "\n",
    "target_urls = pd.read_csv('debate_urls.csv').url.to_list()\n",
    "\n",
    "df = parse_hansard_xml('', memberid2personid_lookup)\n",
    "\n",
    "for url in tqdm(target_urls):\n",
    "    filename = 'debates_xml/'+url.split('/')[-1]\n",
    "    \n",
    "    speech_xml = read_xml_from_path(filename)\n",
    "    debate_df = parse_hansard_xml(speech_xml, memberid2personid_lookup)\n",
    "    \n",
    "    df = df.append(debate_df)\n",
    "    \n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66391910",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "date_from_speech_id = lambda x: pd.to_datetime(x.split('/')[-1][:10])\n",
    "\n",
    "df['speech_date'] = df.speech_id.progress_apply(lambda x: date_from_speech_id(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5570006",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14310554",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv('hansard_in_full.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6.720285,
   "end_time": "2025-10-04T04:36:01.442935",
   "environment_variables": {},
   "exception": true,
   "input_path": "hansard_parser.ipynb",
   "output_path": "hansard_parser.out.ipynb",
   "parameters": {},
   "start_time": "2025-10-04T04:35:54.722650",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}