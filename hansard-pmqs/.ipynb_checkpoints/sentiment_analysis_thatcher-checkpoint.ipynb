{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c14186e",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'debates.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-fa8b4201e73a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdebates_pkl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'debates.pkl'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mdebates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdebates_pkl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdebates_pkl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'debates.pkl'"
     ]
    }
   ],
   "source": [
    "import pickle   \n",
    "\n",
    "debates_pkl = open('debates.pkl','rb')\n",
    "debates = pickle.load(debates_pkl)\n",
    "debates_pkl.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d68d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = debates.keys()\n",
    "pm_answers = dict()\n",
    "loto_questions = dict()\n",
    "\n",
    "for date in dates:\n",
    "    pm_answers[date] = [x['content'] for x in debates[date]['contribs'].values() if x['speaker']==\"The Prime Minister\"]\n",
    "    loto_questions[date] = [x['content'] for x in debates[date]['contribs'].values() if x['speaker'] in [\"Mr. Michael Howard\",\"Mr. Howard\"]]\n",
    "    \n",
    "pm_answers = {k:v for k,v in pm_answers.items() if datetime.strptime(k,\"%Y-%m-%d\") >= datetime.strptime(\"02-05-1997\",\"%d-%m-%Y\")}\n",
    "pm_answers = {k:v for k,v in pm_answers.items() if datetime.strptime(k,\"%Y-%m-%d\") <= datetime.strptime(\"2007-06-27\",\"%Y-%m-%d\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52908b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import regex as re\n",
    "\n",
    "stops = set(stopwords.words('english'))\n",
    "stops = stops.union({'right','hon','friend','gentleman'})\n",
    "\n",
    "def clean_text(text_list):\n",
    "    text = ' '.join(text_list)\n",
    "    \n",
    "    return text\n",
    "    \n",
    "#     # remove newline and tab characters\n",
    "#     text = text.replace(\"\\n\",\" \")\n",
    "#     text = text.replace(\"\\t\",\" \")\n",
    "    \n",
    "#     # strip whitespace\n",
    "#     text = text.strip()\n",
    "    \n",
    "#     # lowercase\n",
    "#     text = text.lower()\n",
    "    \n",
    "#     token_pattern = re.compile(r\"(?u)\\b\\w\\w+\\b\")\n",
    "#     text_list = token_pattern.findall(text)\n",
    "    \n",
    "#     text_list = [word for word in text_list if word not in stops]\n",
    "    \n",
    "#     return text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c176ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b615b02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "for date,answer in pm_answers.items():\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    cleaned_answer = clean_text(answer)\n",
    "    print(cleaned_answer[:100])\n",
    "    ss = sid.polarity_scores(cleaned_answer)\n",
    "    for k in sorted(ss):\n",
    "        print('{0}: {1}, '.format(k, ss[k]), end='')\n",
    "    print()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
